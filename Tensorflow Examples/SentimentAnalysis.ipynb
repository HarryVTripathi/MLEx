{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIg7lJ7c59wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import tarfile\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srxU7OfQ6LBV",
        "colab_type": "code",
        "outputId": "48abe62f-19a1-409d-888a-46fa3d9a5e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDHYfsdE6XjE",
        "colab_type": "code",
        "outputId": "9f20b1a3-1125-49c1-d29c-a05cade5faa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5NfV4P-6ofJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_words():\n",
        "  with zipfile.ZipFile(file='/content/gdrive/My Drive/SentimentAnalysisTensorFlow/ImdbReviews.tar.gz') as myZip:\n",
        "    firstFile = myZip.namelist()[0]\n",
        "    filestring = tf.compat.as_str((myZip.read(firstFile)))\n",
        "    words = filestring.split()\n",
        "\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvg8mX9o7pBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9]+\")\n",
        "\n",
        "def get_reviews(dirname, positive=True):\n",
        "  label = 1 if positive else 0\n",
        "\n",
        "  reviews = []\n",
        "  labels = []\n",
        "\n",
        "  for filename in os.listdir(path=dirname):\n",
        "    if filename.endswith(\".txt\"):\n",
        "      with open(dirname + filename, mode='r+') as f:\n",
        "        review = f.read()\n",
        "        # print(review)\n",
        "        review = review.lower().replace(\"<br />\",\" \")\n",
        "        review = re.sub(TOKEN_REGEX, ' ', review)\n",
        "\n",
        "        reviews.append(review)\n",
        "        labels.append(label)\n",
        "  return reviews, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf4by0K-AZYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_labels_data():\n",
        "  with tarfile.open(name='/content/gdrive/My Drive/SentimentAnalysisTensorFlow/ImdbReviews.tar.gz') as tar:\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "\n",
        "  positive_reviews, positive_labels = get_reviews(\"aclImdb/train/pos/\", positive=True)\n",
        "  negative_reviews, negative_labels = get_reviews(\"aclImdb/train/neg/\", positive=False)\n",
        "\n",
        "  data = positive_reviews + negative_reviews\n",
        "  labels = positive_labels + negative_labels\n",
        "\n",
        "  return labels, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifERaRSBIeUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels, data = extract_labels_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ExPdOoZK802",
        "colab_type": "code",
        "outputId": "00127ca2-d45d-4dd9-da4c-6b86d66cb6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "# pad shorter review, truncate longer reviews\n",
        "# so that all of them are of same length\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_SEQUENCE_LENGTH)\n",
        "x_data = np.array(list(vocab_processor.fit_transform(data)))\n",
        "y_output = np.array(labels)\n",
        "vocabulary_size = len(vocab_processor.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-9-df5aaecf8318>:2: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mkUPGAEIjGX",
        "colab_type": "code",
        "outputId": "a208ae4d-aff2-4770-8c53-85442edf9e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_data[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "         14,  15,  16,  17,  18,  13,  19,  20,  21,   2,  22,  23,  24,\n",
              "         25,  26,  27,  28,  29,  30,  31,  32,  24,  33,  34,  26,  19,\n",
              "         35,  36,  37,  16,  38,  39,  40,  24,  41,  42,  43,  44,  45,\n",
              "         46,  47,   9,  48,  49,  50,  51,  52,  53,  23,  43,  38,  54,\n",
              "         44,  55,  56,  57,  58,  59,  19,  60,  28,  61,  24,  62,  63,\n",
              "         44,  64,  16,  28,  65,  66,  67,  68,  44,  69,  70,  71,  72,\n",
              "         73,  74,  75,  76,  77,  78,   8,   2,   3,  73,  79,  80,  81,\n",
              "         24,  82,  83,  84,  85,  13,  77,  78,  86,  44,  87,  88,  89,\n",
              "         23,  24,  90,  91,  92,  74,  56,  76,  93,  94,  95,  44,  96,\n",
              "         88,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0],\n",
              "       [  9,  19,  44,  20,  97,  98,  99, 100, 101,  63, 102,  13, 103,\n",
              "         43,  44, 104, 105,  25, 106,  91,  99, 107, 108,  44, 109,  13,\n",
              "         91,  56, 110,  44,  69, 111, 112,  10,  65,  44, 113, 114, 115,\n",
              "        116, 117,  19,  10, 118, 119,  55, 120, 121,  73, 122, 123, 124,\n",
              "        125,   5, 126, 127,   1,  99,   3,  44, 100,  68, 128, 129, 119,\n",
              "         24, 130, 131, 132,  24,  44, 100,  43, 133, 134,  74,  56, 135,\n",
              "          7,  83, 136, 137,  24, 138,  53, 139, 140, 131, 141,  24,  74,\n",
              "        133, 142, 143,   9, 100,  74, 113,  24,  56, 113, 144, 145, 146,\n",
              "        147, 148,   7,  53,   2, 100,  13,  91, 149,  10,  65,  44, 113,\n",
              "         57,  99,   3,  13,  91, 133, 150, 151,  99, 152,  53, 133, 153,\n",
              "         65, 154,  44, 107,  74,   1, 155, 156,  38, 157,  24,  19,  38,\n",
              "        158, 159,  75,  44,  47,   9, 111, 160,  80, 161, 146, 111,   5,\n",
              "        162, 163,  44, 164, 107,  16, 165,  24, 166,   5, 167, 168, 146,\n",
              "         65,  44, 169, 170,  24,  68,   5, 171,  44, 172,  44,  47,  16,\n",
              "          9, 100,  74, 173, 174, 175, 176,  43,  44, 177, 178, 179,  44,\n",
              "        180,  63,   1,  43,  44, 177, 178, 181, 163, 182,  99,   5, 183,\n",
              "         44, 107,  13, 184,  44, 185, 133,   1, 186,  24, 187,  10,  43,\n",
              "        188,  24,  56, 181,   5, 189,  44,  14,  99, 190,  44, 134, 180,\n",
              "        191,  14,   1, 186,  43, 188, 192,  65,  73,  65, 193,  99, 194,\n",
              "          5, 195, 125],\n",
              "       [260, 261,  74,  15,   5, 262,  44,  69, 263,  73, 199, 244,  16,\n",
              "         44, 264, 133, 265, 266, 178,  74, 267,   5, 268, 269,  16,  44,\n",
              "        270,  63, 178, 271,   5,   6, 272,  83, 273, 274, 243,  18, 199,\n",
              "        275,   5, 276, 133, 277, 266,  95, 175, 278, 108, 133, 279,  65,\n",
              "        280,  24,  65, 193, 122, 161,   5,   6, 281, 211, 166,  36, 282,\n",
              "        283, 166, 284, 177, 285,  16,  73, 286,  13, 287,  80, 288, 289,\n",
              "          5, 290,  73, 199,  19,  89,   5, 161, 133, 291,  65, 292, 280,\n",
              "         63,  11,   8,  73,  44, 100, 293,  73, 294,   8,  73, 295,  80,\n",
              "          6, 296,  11, 297, 298,  65,  44, 101,  65, 299, 300,  91, 301,\n",
              "         44, 302, 303,  18, 122, 224, 133, 177, 304, 305,  21,  44, 306,\n",
              "         24, 307,   5,   6, 308,  24,  85, 178, 236, 309, 310,  24, 189,\n",
              "        311, 199,  19, 312,  44, 313,  27, 173,  31, 314,  75,  13,  91,\n",
              "        315,   5,  85, 316,  16,  44,   3, 317, 133,  36, 318, 260, 261,\n",
              "        319,  44, 320,  65, 321, 322,  44, 315, 266, 323, 324, 325, 326,\n",
              "        327, 271,   5,   6, 328, 329, 155, 243, 113,  13, 271,   5,   6,\n",
              "        330, 168, 108,  44, 331,  65, 273, 274,   8,  38, 332, 333,  44,\n",
              "        334, 133, 335, 336,  73, 200, 168,  18, 321, 337, 338, 203, 133,\n",
              "        339, 340,  88, 123,  16,  44,  48, 321,  74, 341, 342, 343, 344,\n",
              "         24, 254, 199,  68,   5, 345,  53,  13,  74, 133, 346,  43, 133,\n",
              "        340, 347,  65]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERfmXvnQpJ2",
        "colab_type": "code",
        "outputId": "743d0942-03d7-4e69-c6a0-1cb72d6da2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "data[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['more tv movies ought to be made like this one i saw it way back in 93 when it was first on tv helen hunt and steven weber were both terrific giving very gritty and realistic performances weber was especially good turning in an exceptionally creepy and understated performance as the child molester killer this film really increased my respect for hunt as an actress the director also directed hoosiers which was somehow both formulaic and exciting but the direction in both of these works has the same stark simple realism that is so appealing if you like tv movies that aren t predictable and filled with overacting see it if you can the side story about hunt and fahey s affair is also appealing without detracting from the main story ',\n",
              " 'this was the first regular filmed columbo movie episode but yet it aired as the second after steven spielberg s columbo murder by the book it s also at the same time among one of the better ones bernard l kowalski was one great creative director no wonder that they later asked him to direct three more columbo movies the movie has some real creative and innovative shot sequences and the movie as a whole is also clearly made with style passion and eye for detail every shot connects and is a reason why this movie is better and also better looking just any other average made for tv movie it s definitely one of the better directed columbo movies it s a quit original columbo entry for a couple of reasons the murder is more or less an accident and was an impulsive act so the killer this time doesn t have any time to plan out the perfect murder in advance and his to clean up any of the traces afterward and has to dispose the body the killer in this movie is not only being handled as the man who committed the crime but more as the man who helps out lieutenant columbo to solve the murder it makes the character a more interesting and layered one as well and also helps to make the way columbo solves the whole crime seem way more interesting as well because of that of course columbo starts to suspect him pretty early on and as always he comes to solution by making himself vulnerable and look more stupid than he of course truly is and by gaining the killer s trust this is obviously no spoiler since this is the way every columbo movie gets set up i liked the story of the movie and how it progressed it also helps the movie that it has such a fine cast at the time of this movie peter falk had really made the columbo character his own and the character at this was already fully developed robert culp is truly great as the short tempered brimmer funny thing is that he would later star in three different columbo movies again and one mrs columbo episode only in totally different roles he even played the murderer in a couple of those movies as well again he by the way was not the only actor that did this in other later columbo movies also the great ray milland makes an appearance in this movie as the husband of the victim all in all a real great early columbo movie and among the better ones out of the long running series of movies 9 10',\n",
              " 'jim carrey is back to much the same role that he played in the mask a timid guy who is trying to get ahead in the world but who seems to be plagued with bad luck even when he tries to help a homeless guy from being harassed by a bunch of hoodlums and of course they have to be mexican obviously his good will towards his fellow man backfires in that case it wasn t too hard to predict that he was about to have a handful of angry hoodlums but i like that the movie suggests that things like that shouldn t be ignored i m reminded of the episode of michael moore s brilliant the awful truth when they had a man lay down on the sidewalk and pretend to be dead and see who would actually stop and make sure he was okay the results were not very promising so it s nice to see someone in the movies setting a good example jim carrey plays the part of bruce nolan the nice guy mentioned above whose entire life seems to be falling apart or even better it seems to be breaking up by the blows of bad luck like an asteroid entering the atmosphere a little metaphor that comes up when bruce miraculously finds himself a gigantic news story later in the film bruce is nearly 40 years old and all he has to show for it is a position as a news reporter of the sort that reports on such exciting news as the local bakery that s seeking to bake the world s biggest cookie he s desperate to obtain the job of head anchor at the tv station but he loses his cool on live tv when he hears that the job went to his rival colleague you have to love how they time the revelation of this news to him seconds before his first live report needless to say he loses his temper on live tv in one of the funniest scenes of the entire film morgan freeman delivers a fantastic performance as the man himself displaying a god whose infinite wisdom is somewhat reflected through freeman s massive talent as an actor he is the kind of god who takes his job very seriously but in such a way as to advise his followers as well as the viewers of this movie that there are times when you need to slow down and do some manual labor in life i love his line that some of the happiest people in the world come home smelling to high heaven at the end of the day there are a lot of people in the world maybe more than our share in america who are so absorbed by their money and their possessions and their jobs and everything that they completely lost touch with the natural side of themselves as humans one of the biggest strengths is that the movie is able to provide great advice to people in general about improving their lives and this message is clear and acceptable regardless of the viewer s religion i for example tend to reject organized religion in all forms and i see god and satan to be metaphors for different aspects of nature and human psychology rather than actual figures who ever lived or continue to live but despite the fact that i don t believe that god exists as an entity overseeing the universe or as a janitor dressed all in white who mops the floors of his downtown office in his spare time i was able to appreciate the messages that were delivered in this movie jim carrey s movies display this fantastic evolution that ties them all together and makes the newer ones look even better just because you can see how far he s come if you compare bruce almighty with movies like ace ventura both of which i loved by the way or a lot of what he did before he got into film it s amazing how far he s come he has moved from cheesy tv comedy to cheesy comedic films to comedies that are truly intelligent and meaningful like this film as well as others like the truman show man on the moon and the majestic easily one of his greatest films ever jim carrey has unmistakably moved from the cheesy comedy of his past to become one of the most important comic actors working today jennifer aniston also once again provides an excellent addition to the movie as she did in the side splitting office space as bruce s girlfriend who becomes increasingly exasperated by bruce s growing stress about his life as well as his negligence to ask her to marry him there is definitely some low brow comedy in the film that doesn t really fit with the importance of the film s meaning or the quality of the delivery such as the dog reading the newspaper on the toilet and the whole monkey scene but it was definitely pretty nice to see ace ventura s friend spike make a cameo appearance as stephen king very well knows it s always nice to see familiar characters it s almost like seeing family again bruce is endowed with the powers of god for a given period of time so that he can understand life a bit better and he says a lot about himself when he uses the powers only for his own purposes rather than to help all of the people who pray to him the thing i love about this is that like i said before religion is absent from my life but i was able to watch this and learn a lot about myself as well by thinking about what kinds of things i would have done had i been endowed with such powers the movie allows us to learn vicariously this way which empowers the message even more the scenes that involve the news station are easily the funniest in the entire film such as the scene when bruce loses his temper about the anchor position the jimmy hoffa scene who was conveniently buried with an original birth certificate and a complete set of dental records the scene where bruce s rival colleague is made to go nuts on camera and my favorites the ones at the beginning and the end involving the local bakery s cooking the movie has plenty of time for carrey to deliver some excellent jokes such as when he says to god who reveals that he s the janitor the proprietor the electrician etc that his christmas parties must be real bashes and to be careful about drinking because on of him might need a ride home i also loved the end when he says that behind every great man is a woman rolling her eyes a little too true and as gallagher would add behind every great man is also an amazed mother in law bruce almighty is one of the more memorable comedies to have come out for quite a while and is probably the only directly religious that i can remember seeing that i am anxious to buy on dvd to add to my personal collection it is a comedy written and performed in good taste but with enough relatively low brow humor to keep the kids entertained this is a meaningful comedy for the whole family which is becoming rarer and rarer these days in a world that is about to be flogged with yet another american pie film and another scary movie which are only scary because of their sheer barbarous idiocy it s nice to see that there are still people making comedies worth watching don t miss this one ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SM0HYDYxoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(22)\n",
        "shuffle_indices = np.random.permutation(np.arange(len(x_data)))\n",
        "x_shuffled = x_data[shuffle_indices]\n",
        "y_shuffled = y_output[shuffle_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_s78k3dZOF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = 5000\n",
        "TOTAL_DATA = 6000\n",
        "\n",
        "train_data = x_shuffled[:TRAIN_DATA]\n",
        "train_target = y_shuffled[:TRAIN_DATA]\n",
        "\n",
        "test_data = x_shuffled[TRAIN_DATA: TOTAL_DATA]\n",
        "test_target = y_shuffled[TRAIN_DATA: TOTAL_DATA]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgUDfcDvZyxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(dtype=tf.int32, shape=[None, MAX_SEQUENCE_LENGTH])\n",
        "y = tf.placeholder(dtype=tf.int32, shape=[None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxY4DO73b8IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 20\n",
        "batch_size = 25\n",
        "embedding_size = 50\n",
        "max_label = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC8285ZYcU1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = tf.Variable(\n",
        "    initial_value=tf.random_uniform(\n",
        "        shape=[vocabulary_size, embedding_size],\n",
        "        minval=-1.0,\n",
        "        maxval=1\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6paQ2HfdFdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = tf.nn.embedding_lookup(params=embedding_matrix, ids=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3LNxNJVWifZ",
        "colab_type": "code",
        "outputId": "242f4cb7-181c-4fb4-aa48-25dcd4918bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# shape=[batch_size, n_steps, n_inputs)\n",
        "# n_steps: no of instances in time. n_steps=250 because\n",
        "# the sequence length is 250 and the rnn cell will be\n",
        "# unrolled 250 times in time\n",
        "\n",
        "# the input at any point of time is a single word\n",
        "# and is embedded with a dimensionality of 50 , i.e, n_inputs\n",
        "\n",
        "embeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_lookup/Identity:0' shape=(?, 250, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfHpOu8FWmB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstmCell = tf.contrib.rnn.BasicLSTMCell(embedding_size)\n",
        "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7fRs8hhSnK",
        "colab_type": "code",
        "outputId": "21abafef-1a46-4b4d-f977-2e64af537f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Unrolls the rnn throught the time\n",
        "# encoding is the final state of the rnn\n",
        "_, (encoding, _) = tf.nn.dynamic_rnn(cell=lstmCell, inputs=embeddings, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-c9ef1613f52c>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "345UmnIzteR0",
        "colab_type": "code",
        "outputId": "872607e2-96a1-4c9d-d14d-579b78b04dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXPOCUIat20M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = tf.layers.dense(encoding, max_label)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "    logits=logits,\n",
        "    labels=y\n",
        ")\n",
        "loss = tf.reduce_mean(input_tensor=cross_entropy)\n",
        "optimizer = tf.train.AdamOptimizer(0.01)\n",
        "train_step = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG0NNtNKuIgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output with the highest probability is\n",
        "# the prediction is accurate if predicted label\n",
        "# is equal to the actual label\n",
        "prediction = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0W_HVVnvHBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x_SEGXM1Ln6",
        "colab_type": "code",
        "outputId": "985799b9-e396-4aa9-f8be-b3eeff03d342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    num_batches = int(len(train_data) // batch_size) + 1\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      min_ind = i * batch_size\n",
        "      max_ind = np.min([len(train_data), ((i+1)*batch_size)])\n",
        "\n",
        "      x_train_batch = train_data[min_ind: max_ind]\n",
        "      y_train_batch = train_target[min_ind: max_ind]\n",
        "\n",
        "      train_dict = {x: x_train_batch, y: y_train_batch}\n",
        "      sess.run(train_step, feed_dict=train_dict)\n",
        "      train_loss, train_acc = sess.run([loss, accuracy], feed_dict=train_dict)\n",
        "    \n",
        "    test_dict = {x: test_data, y: test_target}\n",
        "\n",
        "    test_loss, test_acc = sess.run([loss, accuracy], feed_dict=test_dict)\n",
        "\n",
        "    print('Epoch: {}, Test Loss: {:.2}, Test Acc {:.5}' .format(epoch+1, test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Test Loss: 0.7, Test Acc 0.504\n",
            "Epoch: 2, Test Loss: 0.86, Test Acc 0.514\n",
            "Epoch: 3, Test Loss: 1.3, Test Acc 0.616\n",
            "Epoch: 4, Test Loss: 0.81, Test Acc 0.743\n",
            "Epoch: 5, Test Loss: 0.92, Test Acc 0.766\n",
            "Epoch: 6, Test Loss: 1.2, Test Acc 0.775\n",
            "Epoch: 7, Test Loss: 1.3, Test Acc 0.783\n",
            "Epoch: 8, Test Loss: 1.4, Test Acc 0.79\n",
            "Epoch: 9, Test Loss: 1.4, Test Acc 0.789\n",
            "Epoch: 10, Test Loss: 1.5, Test Acc 0.791\n",
            "Epoch: 11, Test Loss: 1.5, Test Acc 0.792\n",
            "Epoch: 12, Test Loss: 1.5, Test Acc 0.793\n",
            "Epoch: 13, Test Loss: 1.6, Test Acc 0.794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-bc5494cf7bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mtrain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE30zhO47RrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}